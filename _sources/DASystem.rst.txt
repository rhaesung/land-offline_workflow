.. _DASystem:

***************************************************
Land Data Assimilation System 
***************************************************

This chapter describes the configuration of the offline Land :term:`Data Assimilation` (DA) System, which utilizes the UFS Noah-MP components and JEDI ``fv3-bundle`` to enable cycled model forecasts.

.. COMMENT: Clarify above!

Joint Effort for Data Assimilation Integration (JEDI)
********************************************************

The Joint Effort for Data assimilation Integration (:term:`JEDI`) is a unified and versatile :term:`data assimilation` (DA) system for Earth System Prediction that can be run on a variety of platforms. JEDI is developed by the Joint Center for Satellite Data Assimilation (`JCSDA <https://www.jcsda.org/>`__) and partner agencies, including NOAA. The core feature of JEDI is separation of concerns. The data assimilation update, observation selection and processing, and observation operators are all coded with no knowledge of or dependency on each other or on the forecast model. 

The NOAH-MP offline Land DA System uses three JEDI components: 
   
   * The Object-Oriented Prediction System (`OOPS <https://jointcenterforsatellitedataassimilation-jedi-docs.readthedocs-hosted.com/en/1.0.0/inside/jedi-components/oops/index.html>`__) for the data assimilation algorithm 
   * The Interface for Observation Data Access (`IODA <https://jointcenterforsatellitedataassimilation-jedi-docs.readthedocs-hosted.com/en/1.0.0/inside/jedi-components/ioda/index.html>`__) for the observation formatting and processing
   * The Unified Forward Operator (`UFO <https://jointcenterforsatellitedataassimilation-jedi-docs.readthedocs-hosted.com/en/1.0.0/inside/jedi-components/ufo/index.html>`__) for comparing model forecasts and observations 

.. COMMENT: And FV3-JEDI bundle? https://jointcenterforsatellitedataassimilation-jedi-docs.readthedocs-hosted.com/en/1.0.0/inside/jedi-components/fv3-jedi/index.html 
   "FV3-JEDI is the interface between the generic components of the JEDI system and models that are based on the FV3 (Finite Volume Cubed-Sphere) dynamical core."

JEDI's Unified Forward Operator (UFO) links observation operators with the Object Oriented Prediction System (OOPS) to compute a simulated observation given a known model state. It does not restrict observation operators based on model-specific code structures or requirements. The UFO code structure provides generic classes for observation bias correction and quality control. Within this system, IODA converts the observation data into model-specific formats to be ingested by each model's data assimilation system. This involves model-specific data conversion efforts. 

Object-Oriented Prediction System (OOPS)
===========================================

A data assimilation experiment requires a ``yaml`` configuration file that specifies the details of the data assimilation and observation processing. OOPS provides the core set of data assimilation algorithms in JEDI by combining the generic building blocks required for the algorithms. The OOPS system does not require knowledge of any specific application model implementation structure or observation data information. In the NOAH-MP offline Land DA System, OOPS reads the model forecast states from the restart files generated by the Noah-MP model. JEDI UFO contains generic quality control options and filters that can be applied to each observation system, without coding at certain model application levels. More information on the key concepts of the JEDI software design can be found in :cite:t:`Tremolet&Auligne2020` (2020), :cite:t:`HoldawayEtAl2020` (2020), and :cite:t:`HoneyagerEtAl2020` (2020).

JEDI Configuration Files
---------------------------

To create the DA experiment, the user should create or modify an experiment-specific configuration ``yaml`` file. This ``yaml`` file should contain certain fundamental components: geometry, window begin, window length, background, driver, local ensemble DA, output increment, and observations. These components can be implemented differently for different models and observations types, so they frequently contain distinct parameters and variable names depending on the use case. Therefore, this section of the User's Guide focuses on assisting users with understanding and customizing these top-level configuration items in order to run Land DA experiments. Users may also reference the `JEDI Documentation <https://jointcenterforsatellitedataassimilation-jedi-docs.readthedocs-hosted.com/en/latest/using/building_and_running/config_content.html>`__ for additional information. 

.. COMMENT: What about: state; model, linear model; model aux control, model aux error; background error (rather than background); initial condition (is this basically included in the backgroun section?); cost function; minimizer; and output

Users may find the following example ``yaml`` configuration file to be a helpful starting point. This file (with user-appropriate modifications) is required by JEDI for snow data assimilation. The following subsections will explain the variables within each top-level item of the ``yaml`` file. 

.. code-block:: console

   geometry:
     fms initialization:
       namelist filename: Data/fv3files/fmsmpp.nml
       field table filename: Data/fv3files/field_table
     akbk: Data/fv3files/akbk64.nc4
     npx: 97
     npy: 97
     npz: 64
     field metadata override: Data/fieldmetadata/gfs-land.yaml
          
     time invariant state fields:
       datetime: 2016-01-02T12:00:00Z
       filetype: fms restart
       skip coupler file: true
       state variables: [orog_filt]
       datapath: /*/
       filename_orog: oro_C96.mx100.nc
    
   window begin: 2016-01-02T12:00:00Z
   window length: PT6H
    
   background:
     date: &date 2016-01-02T18:00:00Z
     members:
       - datetime: 2016-01-02T18:00:00Z
         filetype: fms restart
         state variables: [snwdph,vtype,slmsk]
         datapath: mem_pos/
         filename_sfcd: 20160102.180000.sfc_data.nc
         filename_cplr: 20160102.180000.coupler.res
       - datetime: 2016-01-02T18:00:00Z
         filetype: fms restart
         state variables: [snwdph,vtype,slmsk]
         datapath: mem_neg/
         filename_sfcd: 20160102.180000.sfc_data.nc
         filename_cplr: 20160102.180000.coupler.res
      
   driver:
     save posterior mean: false
     save posterior mean increment: true
     save posterior ensemble: false
     run as observer only: false

   local ensemble DA:
     solver: LETKF
     inflation:
       rtps: 0.0
       rtpp: 0.0
       mult: 1.0

   output increment:
     filetype: fms restart
     filename_sfcd: xainc.sfc_data.nc

   observations:
     observers:
     - obs space:
       name: SnowDepthIMS
       distribution:
         name: Halo
         halo size: 250e3
       simulated variables: [totalSnowDepth]
       observed variables: [totalSnowDepth]
       obsdatain:
         engine:
           type: H5File
           obsfile: ioda.IMSscf.20160102.oro_C96.mx100.nc
       obsdataout:
         engine:
           type: H5File 
           obsfile: output/DA/hofx/letkf_hofx_ims_2016010218.nc
     obs operator:
       name: Identity
     obs error:
       covariance model: diagonal
     obs localizations:
     - localization method: Horizontal SOAR
       lengthscale: 250e3
       soar horizontal decay: 0.000021
       max nobs: 1 
     obs filters:
     - filter: Bounds Check # negative / missing snow
       filter variables:
       - name: totalSnowDepth
         minvalue: 0.0
     - filter: Domain Check # land only
       where:
       - variable:
             name: slmsk@GeoVaLs
           minvalue: 0.5
           maxvalue: 1.5
       - filter: RejectList  # no land-ice
         where:
         - variable:
             name: vtype@GeoVaLs
           minvalue: 14.5
           maxvalue: 15.5
       - filter: Background Check # gross error check
         filter variables:
         - name: totalSnowDepth
         threshold: 6.25
         action:
           name: reject


Geometry
^^^^^^^^^^^

The ``geometry:`` section is used in JEDI configuration files to specify the model grid's parallelization across compute nodes (horizontal and vertical). 

   ``fms initialization``
      This section contains two parameters, ``namelist filename`` and ``field table filename``. 

      .. COMMENT: Come up with better description^ !!!

      ``namelist filename``
         Specifies the path for the namelist filename.

      ``field table filename``
         Specifies the path for the field table filename.

   ``akbk``
      Specifies the path to a file containing the coefficients that define the hybrid sigma-pressure vertical coordinate used in FV3. Files are provided with the repository containing ``ak`` and ``bk`` for some common choices of vertical resolution for GEOS and GFS. 

   ``npx``
      Specifies the number of grid cells in the east-west direction.

      .. COMMENT: "vertices" was used instead of cells originally... Are they vertices like in graph theory (where there are vertices and edges) or vertices like cells in a grid?

   ``npy``
      Specifies the number of grid cells in the north-south direction

   ``npz``
      Specifies the number of vertical layers.

   ``field metadata override``
      Specifies the path for file metadata.

   ``time invariant state fields``
      This parameter contains several subparameters listed below.


      ``datetime``
         Specifies the time in YYYY-MM-DDTHH:00:00Z format, where YYYY is a 4-digit year, MM is a valid 2-digit month, DD is a valid 2-digit day, and HH is a valid 2-digit hour. 

      ``filetype``
         Specifies the type of file.

         .. COMMENT: What are the options?

      ``skip coupler file``
         Specifies whether to enable skipping coupler file. Valid values are: ``true`` | ``false``

         +--------+-----------------+
         | Value  | Description     |
         +========+=================+
         | true   | enable          |
         +--------+-----------------+
         | false  | do not enable   |
         +--------+-----------------+

         .. COMMENT: Check whether ".true./.false."

      ``state variables``
         Specifies the list of state variables. Valid values: ``[orog_filt]``

         .. COMMENT: Need a list of valid options! 

      ``datapath``
         Specifies the path for state variables data.

      ``filename_orog``
         Specifies the name of orographic data file.

Window begin, Window length
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

These two items define the assimilation window for many applications, including Land DA.

``window begin:``
   Specifies the beginning time window. The format is YYYY-MM-DDTHH:00:00Z, where YYYY is a 4-digit year, MM is a valid 2-digit month, DD is a valid 2-digit day, and HH is a valid 2-digit hour.

``window length:``
   Specifies the time window length. The form is PTXXH, where XX is a 2-digit hour.

   .. COMMENT: Sample file has a one-digit hour... What if someone wants to run a longer experiment (i.e. 120 hour forecast)? 


Background
^^^^^^^^^^^^^^
The ``background:`` section includes information on the analysis file(s) (also known as "members") generated by the previous cycle. 

   ``date``
      Specifies the background date. The format is ``&date YYYY-MM-DDTHH:00:00Z``, where YYYY is a 4-digit year, MM is a valid 2-digit month, DD is a valid 2-digit day, and HH is a valid 2-digit hour. For example: ``&date 2016-01-02T18:00:00Z``

   ``members``
      Specifies information on analysis file(s) generated by a previous cycle. 

      .. COMMENT: Verify accuracy

      ``datetime``
         Specifies the time. The format is YYYY-MM-DDTHH:00:00Z, where YYYY is a 4-digit year, MM is a valid 2-digit month, DD is a valid 2-digit day, and HH is a valid 2-digit hour. 

         .. COMMENT: Not the dat & time? And for what? Same as above?

      ``filetype``
         Specifies the type of file. Valid values: ``fms restart``

         .. COMMENT: Other valid values?

      ``state variables``
         Specifies a list of state variables. Valid values: ``[snwdph,vtype,slmsk]``

         .. COMMENT: Are there more?

      ``datapath``
         Specifies the path for state variables data. Valid values: ``mem_pos/`` | ``mem_neg/``

         .. COMMENT: Other valid values?

      ``filename_sfcd``
         Specifies the name of surface data file. This usually takes the form ``YYYYMMDD.HHmmss.sfc_data.nc``, where YYYY is a 4-digit year, MM is a valid 2-digit month, DD is a valid 2-digit day, and HH is a valid 2-digit hour, mm is a valid 2-digit minute and ss is a valid 2-digit second. For example: ``20160102.180000.sfc_data.nc``

         .. COMMENT: Check this!
         
      ``filename_cprl``
         Specifies the name of file that contains metadata for the restart. This usually takes the form ``YYYYMMDD.HHmmss.coupler.res``, where YYYY is a 4-digit year, MM is a valid 2-digit month, DD is a valid 2-digit day, and HH is a valid 2-digit hour, mm is a valid 2-digit minute and ss is a valid 2-digit second. For example: ``20160102.180000.coupler.res``

Driver
^^^^^^^^^

The ``driver:`` section describes optional modifications to the behavior of the LocalEnsembleDA driver. For details, refer to `Local Ensemble Data Assimilation in OOPS <https://jointcenterforsatellitedataassimilation-jedi-docs.readthedocs-hosted.com/en/latest/inside/jedi-components/oops/applications/localensembleda.html>`__ in the JEDI Documentation. 

   .. COMMENT: Check that this is the same as what we're using. If not, note that it is a resource but not 100% the same. 

   ``save posterior mean``
      Specifies whether to save the posterior mean. Valid values: ``true`` | ``false``

      +--------+-----------------+
      | Value  | Description     |
      +========+=================+
      | true   | save            |
      +--------+-----------------+
      | false  | do not save     |
      +--------+-----------------+
      
      .. COMMENT: What is posterior mean?

   ``save posterior mean increment``
      Specifies whether to save the posterior mean increment. Valid values: ``true`` | ``false``

      +--------+-----------------+
      | Value  | Description     |
      +========+=================+
      | true   | enable          |
      +--------+-----------------+
      | false  | do not enable   |
      +--------+-----------------+

      .. COMMENT: What is posterior increment?

   ``save posterior ensemble``
      Specifies whether to save the posterior ensemble. Valid values: ``true`` | ``false``

      +--------+-----------------+
      | Value  | Description     |
      +========+=================+
      | true   | enable          |
      +--------+-----------------+
      | false  | do not enable   |
      +--------+-----------------+

      .. COMMENT: What is posterior ensemble?

   ``run as observer only``
      Specifies whether to run as observer only. Valid values: ``true`` | ``false``

      +--------+-----------------+
      | Value  | Description     |
      +========+=================+
      | true   | enable          |
      +--------+-----------------+
      | false  | do not enable   |
      +--------+-----------------+

      .. COMMENT: What does running as observer only DO?

Local Ensemble DA
^^^^^^^^^^^^^^^^^^^^^

The ``local ensemble DA:`` section configures the local ensemble DA solver package. 
   
   .. COMMENT: Edit/clarify definition?

   ``solver``
      Specifies the type of solver. Currently, ``LETKF`` is the only available option. See :cite:t:`HuntEtAl2007`.

   ``inflation``
      Describes covariance inflation methods. 

      .. COMMENT: Edit definition!

      ``rtps``
         Relaxation to prior spread (:cite:t:`Whitaker&Hamill2012`). 

         .. COMMENT: 0.0

      ``rtpp``
         Relaxation to prior perturbation (:cite:t:`ZhangEtAl2004`). 

         .. COMMENT: 0.0

      ``mult``
         Parameter of multiplicative inflation.

         .. COMMENT: 1.0

         .. COMMENT: Find better definitions and valid values for above variables!

Output Increment
^^^^^^^^^^^^^^^^^^^

   .. COMMENT:
      The ``output increment:`` section...
   
   .. COMMENT: Add definition!

   ``filetype``
      Type of file provided for the output increment. Valid values: ``fms restart``
      
      .. COMMENT: Other valid values?

   ``filename_sfcd``
      Name of the file provided for the output increment. For example: ``xainc.sfc_data.nc``
      
      .. COMMENT: Other valid values? 

Observations
^^^^^^^^^^^^^^^

The ``observations:`` item describes one or more types of observations, each of which is a multi-level YAML/JSON object in and of itself. Each of these observation types is read into JEDI as an ``eckit::Configuration`` object (see `JEDI Documentation <https://jointcenterforsatellitedataassimilation-jedi-docs.readthedocs-hosted.com/en/1.0.0/using/building_and_running/config_content.html#observations>`__ for more details).

   ``observers``

      .. COMMENT: Need def!

``obs space:``
````````````````

The ``obs space:`` section of the ``yaml`` comes under the ``observations.observers:`` section and describes the configuration of the observation space. An observation space handles observation data for a single observation type. 

   ``name``
      Specifies the name of observation space. Since the Land DA System uses IMS snow depth data, the sample configuration file uses the name ``SnowDepthIMS``. 

      .. COMMENT: Check whether this can be any name that makes sense to the user or whether there are particular values.

   ``distribution``

      .. COMMENT Add def here!!

      ``name``
         Specifies the name of distribution. Valid values: ``Halo`` | InefficientDistribution

         .. COMMENT: Other valid values? Can InefficientDistribution be used with Land DA?

      ``halo size``
         Specifies the size of the halo distribution. Valid values: ``250e3``

         .. COMMENT: Other valid values?

   ``simulated variables``
      Specifies the list of variables that need to be simulated by observation operator. Valid values: ``[totalSnowDepth]``

   ``observed variables``
      Specifies the list of observed variables. Valid values: ``[totalSnowDepth]``

      .. COMMENT: Add complete list of valid values to the 2 variables above!

   ``obsdatain``
      This section specifies information about the observation input data.

      ``engine``
         This section specifies parameters required for the file matching engine.  

         ``type``
            Specifies the type of input observation data. Valid values: ``H5File`` | ``OBS``

         ``obsfile``
            Specifies the input filename.

            .. COMMENT: Add Valid/recommended value? ``ioda.IMSscf.20160102.oro_C96.mx100.nc``

   ``obsdataout``
      This section contains information about the observation output data.

      ``engine``
         This section specifies parameters required for the file matching engine. 

         ``type``
            Specifies the type of output observation data. Valid values: ``H5File``

         ``obsfile``
            Specifies the output file path. 

            .. COMMENT: Add Valid/recommended value? ``output/DA/hofx/letkf_hofx_ims_2016010218.nc``

``obs operator:``
````````````````````

The ``obs operator:`` section describes the observation operator and its options. An observation operator is used for computing H(x).

   .. COMMENT: Explain more!!! 

   ``name``
      Specifies the name in the ``ObsOperator`` and ``LinearObsOperator`` factory, defined in the C++ code. Valid values include: ``Identity`` | ``Composite`` | ``Categorical``. See `JEDI Documentation <https://jointcenterforsatellitedataassimilation-jedi-docs.readthedocs-hosted.com/en/latest/inside/jedi-components/ufo/obsops.html>`__ for more options. 

      .. COMMENT: There are a ton of options, but which ones will work? Is Identity the only valid one?

``obs error:``
``````````````````

The ``obs error:`` section explains how to calculate the observation error covariance matrix and gives instructions (required for DA applications). The key covariance model, which describes how observation error covariances are created, is frequently the first item in this section. For diagonal observation error covariances, only the diagonal option is currently supported.

   ``covariance model``
      Specifies the covariance model. Valid values: ``diagonal``

      .. COMMENT: Get other valid values! ``cross variable covariances``

``obs localizations:``
````````````````````````
   .. COMMENT:
      The ``obs localizations:`` section describes...

   .. COMMENT: Get def!!!

   ``localization method``
      Specifies the observation localization method. Valid values include: ``Horizontal SOAR``

      +-----------------+-----------------------------------------------+
      | Value           | Description                                   |
      +=================+===============================================+
      | Horizontal SOAR | Second Order Auto-Regressive localization in  |
      |                 | the horizontal direction.                     |
      +-----------------+-----------------------------------------------+

   ``lengthscale``
      Radius of influence (i.e., maximum distance of observations from the location being updated) in meters. Format is e-notation. For example: ``250e3``
      
   ``soar horizontal decay``
      Decay scale of SOAR localization function.
               
      .. COMMENT: Check/improve definition!
         Valid values: ``0.000021``

   ``max nobs``
      Maximum number of observations used to update each location. 

``obs filters:``
``````````````````

Observation filters are used to define Quality Control (QC) filters. They have access to observation values and metadata, model values at observation locations, simulated observation value, and their own private data. See `Observation Filters <https://jointcenterforsatellitedataassimilation-jedi-docs.readthedocs-hosted.com/en/latest/inside/jedi-components/ufo/qcfilters/introduction.html#observation-filters>`__ in the JEDI Documentation for more detail. The ``obs filters:`` section contains the following fields:

   ``filter``
      Describes the parameters of a given QC filter. Valid values include: ``Bounds Check`` | ``Background Check`` | ``Domain Check`` | ``RejectList``. See descriptions in the JEDI's `Generic QC Filters <https://jointcenterforsatellitedataassimilation-jedi-docs.readthedocs-hosted.com/en/latest/inside/jedi-components/ufo/qcfilters/GenericQC.html>`__ Documentation for more. 

      +--------------------+--------------------------------------------------+
      | Filter Name        | Description                                      |
      +====================+==================================================+
      | Bounds Check       | Rejects observations whose values lie outside    |
      |                    | specified limits:                                |
      +--------------------+--------------------------------------------------+
      | Background Check   | This filter checks for bias-corrected distance   |
      |                    | between the observation value and model-simulated|
      |                    | value (*y* - *H(x)*) and rejects observations    |
      |                    | where the absolute difference is larger than     |
      |                    | the ``absolute threshold`` or ``threshold`` *    |
      |                    | *observation error* or ``threshold`` *           |
      |                    | *background error*.                              |
      +--------------------+--------------------------------------------------+
      | Domain Check       | This filter retains all observations selected by |
      |                    | the ``where`` statement and rejects all others.  |
      +--------------------+--------------------------------------------------+
      | RejectList         | This is an alternative name for the BlackList    |
      |                    | filter, which rejects all observations selected  |
      |                    | by the ``where`` statement. The status of all    |
      |                    | others remains the same. Opposite of Domain      |
      |                    | Check filter.                                    |
      +--------------------+--------------------------------------------------+
         
   ``filter variables``
      Limit the action of a QC filter to a subset of variables or to specific channels. 

      ``name``
         Name of the filter variable. Users may indicate additional filter variables using the ``name`` field on consecutive lines (see code snippet below). Valid values: ``totalSnowDepth``

         .. COMMENT: Are there other valid values? Add code snippet with example of multiple names or delete comment. 

         .. code-block:: console

            filter variables:
            - name: variable_1
            - name: variable_2

   ``minvalue``
      Minimum value for variables in the filter. 

   ``maxvalue``
      Maximum value for variables in the filter. 

   ``threshold``
      This variable may function differently depending on the filter it is used in. In the `Background Check Filter <https://jointcenterforsatellitedataassimilation-jedi-docs.readthedocs-hosted.com/en/latest/inside/jedi-components/ufo/qcfilters/GenericQC.html#background-check-filter>`__, an observation is rejected when the difference between the observation value (*y*) and model simulated value (*H(x)*) is larger than the ``threshold`` * *observation error*. 

   ``action``
      Indicates which action to take once an observation has been flagged by a filter. See `Filter Actions <https://jointcenterforsatellitedataassimilation-jedi-docs.readthedocs-hosted.com/en/latest/inside/jedi-components/ufo/qcfilters/FilterOptions.html#filter-actions>`__ in the JEDI documentation for a full explanation and list of valid values. 

      ``name``
         The name of the desired action. Valid values include: ``accept`` | ``reject``

   ``where``
      By default, filters are applied to all filter variables listed. The ``where`` keyword applies a filter only to observations meeting certain conditions. See the `Where Statement <https://jointcenterforsatellitedataassimilation-jedi-docs.readthedocs-hosted.com/en/latest/inside/jedi-components/ufo/qcfilters/FilterOptions.html#where-statement>`__ section of the JEDI Documentation for a complete description of valid ``where`` conditions. 
               
      ``variable``
         A list of variables to check using the ``where`` statement. 

         ``name``
            Name of a variable to check using the ``where`` statement. Multiple variable names may be listed under ``variable``. The conditions in the where statement will be applied to all of them. For example: 

            .. code-block:: console

               filter: Domain Check # land only
                 where:
                 - variable:
                     name: variable_1
                     name: variable_2
                   minvalue: 0.5
                   maxvalue: 1.5

      ``minvalue``
         Minimum value for variables in the ``where`` statement.

      ``maxvalue``
         Maximum value for variables in the ``where`` statement.

.. _IODA:

Interface for Observation Data Access (IODA)   
===============================================

*This section references Honeyager, R., Herbener, S., Zhang, X., Shlyaeva, A., and Trémolet, Y., 2020: Observations in the Joint Effort for Data assimilation Integration (JEDI) - UFO and IODA. JCSDA Quarterly, 66, Winter 2020.*

The Interface for Observation Data Access (IODA) is a subsystem of JEDI that can handle data processing for various models, including the Land DA System. Currently, observation data sets come in a variety of formats (e.g., netCDF, BUFR, GRIB) and may differ significantly in structure, quality, and spatiotemporal resolution/density. Such data must be pre-processed and converted into model-specific formats. This process often involves iterative, model-specific data conversion efforts and numerous cumbersome ad-hoc approaches to prepare observations. Requirements for observation files and I/O handling often result in decreased I/O and computational efficiency. IODA addresses this need to modernize observation data management and use in conjunction with the various components of the Unified Forecast System (:term:`UFS`).

IODA provides a unified, model-agnostic method of sharing observation data and exchanging modeling and data assimilation results. The IODA effort centers on three core facets: (i) in-memory data access, (ii) definition of the IODA file format, and (iii) data store creation for long-term storage of observation data and diagnostics. The combination of these foci enables optimal isolation of the scientific code from the underlying data structures and data processing software while simultaneously promoting efficient I/O during the forecasting/DA process by providing a common file format and structured data storage.

The IODA file format represents observational field variables (e.g., temperature, salinity, humidity) and locations in two-dimensional tables, where the variables are represented by columns and the locations by rows. Metadata tables are associated with each axis of these data tables, and the location metadata hold the values describing each location (e.g., latitude, longitude). Actual data values are contained in a third dimension of the IODA data table; for instance: observation values, observation error, quality control flags, and simulated observation (H(x)) values.

Since the raw observational data come in various formats, a diverse set of "IODA converters" exists to transform the raw observation data files into IODA format. While many of these Python-based IODA converters have been developed to handle marine-based observations, users can utilize the "IODA converter engine" components to develop and implement their own IODA converters to prepare arbitrary observation types for data assimilation within JEDI. (See https://github.com/NOAA-PSL/land-DA_update/blob/develop/jedi/ioda/imsfv3_scf2ioda_obs40.py for the land DA IMS IODA converter.)

Observation Data
*******************

Observation Types
====================

IMS Snow and Ice Coverage
----------------------------

The Land DA System utilizes snow and ice coverage observations derived from the U.S. National Ice Center (USNIC) Interactive Multisensor Snow and Ice Mapping System (`IMS <https://usicecenter.gov/Products/ImsHome>`__). The IMS includes data retrieved by several different platforms using several different sensors (see `here <https://nsidc.org/data/g02156/versions/1>`__ for specifics). 

The USNIC IMS provides daily analyses of Northern Hemisphere snow and ice coverage at 1-km and 4-km resolutions in ASCII, GRIB, and GeoTIFF format. The geographic domain covered by the data is 0-90ºN and 180ºE to -180ºW. According to the :cite:t:`NSIDC2008`, "Data are in a polar stereographic projection centered at 90° N with the vertical longitude from the Pole at 80° W and the standard parallel at 60° N." For ingestion into the Land DA System, the 4-km analyses (6144 x 6144 grid cells) in ASCII format are first converted to :term:`netCDF` format (``.nc``) and then processed by JEDI's IODA component. (Specifically, the Land DA example forecast uses ``ims2016002_4km_v1.3.nc``, which was converted from ``NIC.IMS_v3_201600200_4km.asc``). The IMS snow and ice cover netCDF files contain the following primary fields (:cite:t:`NSIDC2008`, p. 9): 

   * ``IMS_Surface_Values``: The surface types in the IMS product: open water, land, sea/lake ice, and snow cover. 
      
      +-----------+--------------------------+
      | Variable  | Description              |
      +===========+==========================+
      | 0         | Outside Coverage Area    |
      +-----------+--------------------------+
      | 1         | Open Water               |
      +-----------+--------------------------+
      | 2         | Land Without Snow        |
      +-----------+--------------------------+
      | 3         | Sea Ice or Lake Ice      |
      +-----------+--------------------------+
      | 4         | Snow-Covered Land        |
      +-----------+--------------------------+

   * ``projection``: Projection description for the data.
   * ``time``: The time stamp for the data in seconds since 1970-01-01T00:00:00Z. This is the 00Z reference time. Note that products are nowcasted to be valid specifically at the time given here. 
   * ``x``: X coordinate of grid cell. Values, in meters, are the centers of the grid cells.
   * ``y``: Y coordinate of grid cell. Values, in meters, are the centers of the grid cells.

.. note::

   Users can view additional file information and notes using the ``ncdump`` module. For example: 

   .. code-block:: console

      ncdump -h </path_to_ims_netcdf_file/file_name.nc>

GHCN Snow Depth
------------------

Snow depth observations are taken from the `Global Historical Climatology Network <https://www.ncei.noaa.gov/products/land-based-station/global-historical-climatology-network-daily>`__, which provides daily climate summaries sourced from a global network of 100,000 stations. NOAA's `NCEI <https://www.ncei.noaa.gov/>`__ provides access to these snow depth and snowfall measurements through daily-generated, individual station ASCII files or GZipped tar files of full-network observations via the NCEI server or Climate Data Online. Alternatively, users may acquire yearly tarballs via ``wget``:

.. code-block:: console

   wget https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/{YYYY}.csv.gz ,


where ``${YYYY}`` should be replaced with the year of interest. Note that these yearly tarballs contain all measurement types from the daily GHCN output, and thus, snow depth must be manually extracted from this broader data set.

As with the raw IMS data, these raw snow depth observations need to be converted into IODA-formatted netCDF files for ingestion into the JEDI LETKF system. However, this process was preemptively handled outside of the Land DA workflow, and the initial GHCN IODA files for 2016, 2020, and 2021 were provided by NOAA PSL (Clara Draper, Mike Barlage).

The IODA-formatted GHCN files are structured as follows (using 20160701 as an example):

.. code-block:: console
   
   netcdf ghcn_snwd_ioda_20160701 {
   dimensions:
      nlocs = UNLIMITED ; // (7573 currently)
   variables:
      int nlocs(nlocs) ;
         nlocs:suggested_chunk_dim = 7573LL ;

      // global attributes:
         string :_ioda_layout = "ObsGroup" ;
         :_ioda_layout_version = 0 ;
         string :converter = "ghcn_snod2ioda_newV2.py" ;
         string :date_time_string = "2016-07-01T18:00:00Z" ;
         :nlocs = 7573 ;
         :history = "Fri Aug 12 21:10:02 2022: ncrename -O -v altitude,height ./data_proc_test/nc4_ghcn_snwd_ioda_20160701.nc ./data_proc_Update/ghcn_snwd_ioda_20160701.nc" ;
         :NCO = "netCDF Operators version 4.9.1 (Homepage = http://nco.sf.net, Code = http://github.com/nco/nco)" ;

   group: MetaData {
      variables:
         string datetime(nlocs) ;
            string datetime:_FillValue = "" ;
         float latitude(nlocs) ;
            latitude:_FillValue = 9.96921e+36f ;
            string latitude:units = "degrees_north" ;
         float longitude(nlocs) ;
            longitude:_FillValue = 9.96921e+36f ;
            string longitude:units = "degrees_east" ;
         string stationIdentification(nlocs) ;
            string stationIdentification:_FillValue = "" ;
         float height(nlocs) ;
            height:_FillValue = 9.96921e+36f ;
      } // group MetaData

   group: ObsError {
   variables:
         float totalSnowDepth(nlocs) ;
            totalSnowDepth:_FillValue = 9.96921e+36f ;
            string totalSnowDepth:coordinates = "longitude latitude" ;
            string totalSnowDepth:units = "mm" ;
      } // group ObsError

   group: ObsValue {
      variables:
         float totalSnowDepth(nlocs) ;
            totalSnowDepth:_FillValue = 9.96921e+36f ;
            string totalSnowDepth:coordinates = "longitude latitude" ;
            string totalSnowDepth:units = "mm" ;
      } // group ObsValue

   group: PreQC {
      variables:
         int totalSnowDepth(nlocs) ;
            totalSnowDepth:_FillValue = -2147483647 ;
            string totalSnowDepth:coordinates = "longitude latitude" ;
      } // group PreQC
   }

The primary observation variable is ``totalSnowDepth``, which, along with the metadata fields of ``datetime``, ``latitude``, ``longitude``, and ``height`` is defined along the ``nlocs`` dimension. Also present are ``ObsError`` and ``PreQC`` values corresponding to each ``totalSnowDepth`` measurement on ``nlocs``. These values were attributed during the IODA conversion step. The magnitude of ``nlocs`` varies between files; this is due to the fact that the number of stations reporting snow depth observations for a given day can vary in the GHCN.

Observation Location and Processing
======================================

GHCN
-------

GHCN files for 2016, 2020, and 2021 are already provided in IODA format. :numref:`Table %s <DataLocations>` indicates where users can find data on Level 1 platforms. Tar files containing the 2016 and 2020 data are located in the publicly-available `Land DA Data Bucket <https://noaa-ufs-land-da-pds.s3.amazonaws.com/index.html>`__ (there is currently no 2021 tar file). Once untarred, the snow depth files are located in ``/inputs/DA/snow_depth/GHCN/data_proc/<year>``.  These GHCN IODA files were provided by NOAA PSL (Clara Draper, Mike Barlage). Each file follows the naming convention of ``ghcn_snwd_ioda_${YYYY}${MM}${DD}.nc``, where ``${YYYY}`` is the four-digit cycle year, ``${MM}`` is the two-digit cycle month, and ``${DD}`` is the two-digit cycle day. 

.. _DataLocations:

.. table:: Data Locations on Level 1 Systems

   +-----------+-----------------------------------------------------------------------------+
   | Platform  | Data Path                                                                   |
   +===========+=============================================================================+
   | Hera      | /scratch1/NCEPDEV/nems/role.epic/landda/inputs/DA/snow_depth/GHCN/data_proc |
   +-----------+-----------------------------------------------------------------------------+
   | Orion     | /work/noaa/epic-ps/role-epic-ps/landda/inputs/DA/snow_depth/GHCN/data_proc  |
   +-----------+-----------------------------------------------------------------------------+


In each experiment, the ``DA_config`` file sets the name of the experiment configuration file. This configuration file is typically named ``settings_DA_test``. Before assimilation, if "GHCN" was specified as the observation type in the ``DA_config`` file, the ``ghcn_snwd_ioda_${YYYY}${MM}${DD}.nc`` file corresponding to the specified cycle date is soft-linked to the JEDI working directory (``${JEDIWORKDIR}``) with a naming-convention change (i.e., ``GHCN_${YYYY}${MM}${DD}${HH}.nc``). Here, the GHCN IODA file is appended with the cycle hour, ``${HH}`` which is extracted from the ``${STARTDATE}`` variable defined in the relevant ``DA_config`` file. 

Prior to ingesting the GHCN IODA files via the LETKF at the DA analysis time, the observations are further quality controlled and checked using ``letkf_land.yaml`` (itself a concatenation of ``GHCN.yaml`` and ``letkfoi_snow.yaml``; see the `GitHub yaml files <https://github.com/NOAA-EPIC/land-DA_update/tree/31191c913a624d7fab479dc429d44ff102cd3809/jedi/fv3-jedi/yaml_files>`__ for more detail). The GHCN-specific observation filters, domain checks, and quality control parameters from ``GHCN.yaml`` ensure that only snow depth observations which meet specific criteria are assimilated (the rest are rejected). The contents of this YAML are listed below:

.. code-block:: console

   - obs space:
         name: Simulate
         distribution: 
         name: Halo
         halo size: 250e3
         simulated variables: [totalSnowDepth]
         obsdatain:
         engine:
            type: H5File
            obsfile: GHCN_XXYYYYXXMMXXDDXXHH.nc
         obsdataout:
         engine:
            type: H5File
            obsfile: output/DA/hofx/letkf_hofx_ghcn_XXYYYYXXMMXXDDXXHH.nc
      obs operator:
         name: Identity
      obs error:
         covariance model: diagonal
      obs localizations:
      - localization method: Horizontal SOAR
         lengthscale: 250e3
         soar horizontal decay: 0.000021
         max nobs: 50
      - localization method: Vertical Brasnett
         vertical lengthscale: 700
      obs filters:
      - filter: Bounds Check # negative / missing snow
         filter variables:
         - name: totalSnowDepth
         minvalue: 0.0
      - filter: Domain Check # missing station elevation (-999.9)
         where:
         - variable:
            name: height@MetaData
         minvalue: -999.0
      - filter: Domain Check # land only
         where:
         - variable:
            name: slmsk@GeoVaLs
         minvalue: 0.5
         maxvalue: 1.5
      # GFSv17 only.
      #- filter: Domain Check # no sea ice
      #  where:
      #  - variable:
      #      name: fraction_of_ice@GeoVaLs
      #    maxvalue: 0.0
      - filter: RejectList  # no land-ice
         where:
         - variable:
            name: vtype@GeoVaLs
         minvalue: 14.5
         maxvalue: 15.5
      - filter: Background Check # gross error check
         filter variables:
         - name: totalSnowDepth
         threshold: 6.25
         action:
         name: reject


IMS
------

Pre-processed/Raw Observations
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The raw IMS observation file(s) (already in netCDF) for the Land DA System are located in ``/inputs/DA/snow_ice_cover/IMS/2016`` (``inputs`` is the top-level directory in the ``landda-data-2016.tar.gz`` tarball from the `Land DA Data Bucket <https://noaa-ufs-land-da-pds.s3.amazonaws.com/index.html#current_land_da_release_data/>`__). 

Processing steps in ``do_landDA.sh``
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Before the raw observations can be assimilated using JEDI LETKF, they must be processed (i.e., derived fields calculated, re-gridded, quality controlled/filtered). This processing is handled in the ``do_landDA.sh`` bash script through the call of two key components: (i) the ``IMS_proc`` ``calcfIMS`` executable and (ii) the IMS IODA converter (see ``do_landDA.sh`` lines 210-228, below).

.. COMMENT: Are these line numbers still valid...?

.. code-block:: console

      echo 'do_landDA: calling fIMS'
   #  source ${LANDDADIR}/land_mods_hera
      ${calcfIMS_EXEC}
      if [[ $? != 0 ]]; then
         echo "fIMS failed"
         exit 10
      fi

      IMS_IODA=imsfv3_scf2ioda_obs40.py
      cp ${LANDDADIR}/jedi/ioda/${IMS_IODA} $WORKDIR

      echo 'do_landDA: calling ioda converter'
   #  source ${LANDDADIR}/ioda_mods_hera

      ${PYTHON} ${IMS_IODA} -i IMSscf.${YYYY}${MM} {DD}.${TSTUB}.nc -o ${WORKDIR}ioda.IMSscf. {YYYY}${MM}${DD}.${TSTUB}.nc
      if [[ $? != 0 ]]; then
         echo "IMS IODA converter failed"
         exit 10
      fi

``calcfIMS``
^^^^^^^^^^^^^^^

Before being passed through an IODA converter, the raw IMS netCDF files are first called by the ``calcfIMS`` executable which, through the application of various subroutines, calculates (i) snow cover fraction over land, (ii) snow water equivalent (SWE), and (iii) snow depth based upon the snow-cover fraction/SWE through an inversion of the NoahMP snow depletion curve. These fields are determined on the model grid (UFS NoahMP) and written to an intermediate file called ``IMSscf.${YYYY}${MM}${DD}.${TSTUB}.nc``, where ``${YYYY}`` is the cycle year, ``${MM}`` is the cycle month, ``${DD}`` is the cycle day, and ``${TSTUB}`` is the orography type (``C${RES}`` [atm] or ``C${RES}.mx100`` [coupled atm/ocean], where ``${RES}`` is the FV3 model resolution). 

The source code of the ``calcfIMS`` executable can be found `here <https://www.google.com/url?q=https://github.com/NOAA-PSL/land-IMS_proc/tree/develop/sorc&sa=D&source=docs&ust=1677116607366107&usg=AOvVaw3QCUpymGRdD-fHeVEZKI91>`__ and is located locally in ``land-offline_workflow/DA_update/IMS_proc/sorc`` (see ``driver_fIMS.f90`` and ``IMSaggregate_mod.f90``). After building (compiling) the Land DA System, the ``calcfIMS.exe`` can be found in ``${PATH_TO_LAND_OFFLINE_WORKLOW}/build/bin``. 


IODA-Converted Observatons
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Before assimilating the IMS data, the intermediate (post-``calcfIMS``) observation files (i.e., ``IMSscf.${YYYY}${MM}${DD}.${TSTUB}.nc``-type files)  must be processed using a JEDI IODA converter to transform IMS file fields and attributes into IODA format. For the land DA system, the converter used is ``imsfv3_scf2ioda_obs40.py`` (available on GitHub `here <https://github.com/NOAA-EPIC/land-DA_update/blob/develop/jedi/ioda/imsfv3_scf2ioda_obs40.py>`__) 

The primary component of this IODA converter is the ``imsFV3`` class, which does the bulk of the observational file preparation and translation into IODA format. Snow cover fraction and snow depth observation location, timestamp, and magnitude are extracted from ``IMSscf.${YYYY}${MM}${DD}.${TSTUB}.nc`` and translated into the IODA variables ``snowCoverFraction`` and ``totalSnowDepth`` on the IODA-format dimension (``nlocs``), with the additional metadata variables ``datetime``, ``height``, ``latitude``, and ``longitude`` also defined along the ``nlocs`` dimension. Each snow cover fraction and snow depth observation is also assigned error and quality control values at each point on ``nlocs``. This conversion follows the 2-D/3-D data table paradigm outline in `Section %s <IODA>`. 

After conversion into the IODA format, the new fields/variables are written to netCDF format. The IODA-converted files adhere to the following naming convention: ``ioda.IMSscf.${YYYY}${MM}${DD}.${TSTUB}.nc``, where again ``${YYYY}`` is the cycle year, ``${MM}`` is the cycle month, ``${DD}`` is the cycle day, and ``${TSTUB}`` is the orography type (``C${RES}`` [atm] or ``C${RES}.mx100`` [coupled atm/ocean], where ``${RES}`` is the FV3 model resolution). In the example forecast/analysis used throughout this document, the resultant IODA file is called ``ioda.IMSscf.20160101.oro_C96.mx100.nc``. Such IODA files have the following format/content:

.. code-block:: console

   netcdf ioda.IMSscf.20160101.oro_C96.mx100 {
   dimensions:
      nlocs = UNLIMITED ; // (12283 currently)
   variables:
      int nlocs(nlocs) ;
         nlocs:suggested_chunk_dim = 10000LL ;

   // global attributes:
         string :_ioda_layout = "ObsGroup" ;
         :_ioda_layout_version = 0 ;
         string :converter = "imsfv3_scf2ioda_obs40.py" ;
         string :sensor = "IMS Multisensor" ;
         string :date_time_string = "2016-01-01T18:00:00Z" ;
         :nlocs = 12283 ;

   group: MetaData {
      variables:
         string datetime(nlocs) ;
            string datetime:_FillValue = "" ;
         float height(nlocs) ;
            height:_FillValue = 9.96921e+36f ;
            string height:units = "m" ;
         float latitude(nlocs) ;
            latitude:_FillValue = 9.96921e+36f ;
            string latitude:units = "degrees_north" ;
         float longitude(nlocs) ;
            longitude:_FillValue = 9.96921e+36f ;
            string longitude:units = "degrees_east" ;
      } // group MetaData

   group: ObsError {
      variables:
         float snowCoverFraction(nlocs) ;
            snowCoverFraction:_FillValue = -999.f ;
            string snowCoverFraction:coordinates = "longitude latitude" ;
            string snowCoverFraction:units = "1" ;
         float totalSnowDepth(nlocs) ;
            totalSnowDepth:_FillValue = -999.f ;
            string totalSnowDepth:coordinates = "longitude latitude" ;
            string totalSnowDepth:units = "mm" ;
      } // group ObsError

   group: ObsValue {
      variables:
         float snowCoverFraction(nlocs) ;
            snowCoverFraction:_FillValue = -999.f ;
            string snowCoverFraction:coordinates = "longitude latitude" ;
            string snowCoverFraction:units = "1" ;
         float totalSnowDepth(nlocs) ;
            totalSnowDepth:_FillValue = -999.f ;
            string totalSnowDepth:coordinates = "longitude latitude" ;
            string totalSnowDepth:units = "mm" ;
      } // group ObsValue

   group: PreQC {
      variables:
         int snowCoverFraction(nlocs) ;
            snowCoverFraction:_FillValue = -999 ;
            string snowCoverFraction:coordinates = "longitude latitude" ;
            string snowCoverFraction:units = "unitless" ;
         int totalSnowDepth(nlocs) ;
            totalSnowDepth:_FillValue = -999 ;
            string totalSnowDepth:coordinates = "longitude latitude" ;
            string totalSnowDepth:units = "unitless" ;
      } // group PreQC
   }

.. COMMENT: Check spacing/indentation

Set and Submit the DA Cycle 
****************************** 

This chapter explains how to set up and run the Noah-MP offline DA system. Users should expect to run the given snow data assimilation example using the Global Historical Climatology Network (GHCN) snow depth observations and also create their own experiment by modifying the set-up to suit user goals.

Input Files
==============

The DA system requires grid description files and restart files. 

Grid Description Files
---------------------------

The grid description files appear in :numref:`Section %s <V2TInputFiles>` and are also used as input files to the Vector-to-Tile Converter. See :numref:`Table %s <GridInputFiles>` for a description of these files. 

Restart Files
------------------

To restart the ``ufs-land-driver`` successfully after land model execution, all parameters, states, and fluxes that are used in the subsequent time iteration are stored in a restart file. The Noah-MP offline Land DA System reads the to-be-updated states from the restart file and replaces them after the DA step with the updated analysis. Within the ufs-land-driver, read/write of the restart file is performed in ``ufsLandNoahMPRestartModule.f90``. 

The Noah-MP Offline Land DA System reads a restart file named ``ufs_land_restart.{FILEDATE}.nc`` where ``FILEDATE`` is in YYYY-MM-DD_HH-mm-SS format (e.g., ``ufs_land_restart.2016-01-02_18-00-00.nc``). The restart file contains all the model fields and their values at a specific point in time; this information can be used to restart the model immediately to run the next cycle. :numref:`Table %s <RestartFiles>` lists the fields in the Land DA System restart file. 

.. COMMENT: Combine two paragraphs above cohesively!

.. _RestartFiles:

.. table:: Files Included in ufs_land_restart.{FILEDATE}.nc

   +--------------------------+-----------------------------------+-----------------------+
   | Variable                 | Long name                         | Unit                  | 
   +==========================+===================================+=======================+
   | time                     | time                              | "seconds since        |
   |                          |                                   | 1970-01-01 00:00:00"  |
   +--------------------------+-----------------------------------+-----------------------+
   | timestep                 | time step                         | "seconds"             |
   +--------------------------+-----------------------------------+-----------------------+
   | vegetation_fraction      | Vegetation fraction               | "-"                   |
   +--------------------------+-----------------------------------+-----------------------+
   | emissivity_total         | surface emissivity                | "-"                   |
   +--------------------------+-----------------------------------+-----------------------+
   | albedo_direct_vis        | surface albedo - direct visible   | "-"                   |
   +--------------------------+-----------------------------------+-----------------------+
   | albedo_direct_nir        | surface albedo - direct NIR       | "-"                   |
   +--------------------------+-----------------------------------+-----------------------+
   | albedo_diffuse_vis       | surface albedo - diffuse visible  | "-"                   |
   +--------------------------+-----------------------------------+-----------------------+
   | albedo_diffuse_nir       | surface albedo - diffuse NIR      | "-"                   |
   +--------------------------+-----------------------------------+-----------------------+
   | temperature_soil_bot     | deep soil temperature             | "K"                   |
   +--------------------------+-----------------------------------+-----------------------+
   | cm_noahmp                | surface exchange coefficient      | "m/s"                 |
   |                          | for momentum                      |                       |
   +--------------------------+-----------------------------------+-----------------------+
   | ch_noahmp                | surface exchange coefficient      | "m/s"                 |
   |                          | heat & moisture                   |                       |
   +--------------------------+-----------------------------------+-----------------------+
   | forcing_height           | height of forcing                 | "m"                   |
   +--------------------------+-----------------------------------+-----------------------+
   | max_vegetation_frac      | maximum fractional coverage of    | "fraction"            |
   |                          | vegetation                        |                       |
   +--------------------------+-----------------------------------+-----------------------+
   | albedo_total             | grid composite albedo             | "fraction"            |
   +--------------------------+-----------------------------------+-----------------------+
   | snow_water_equiv         | snow water equivalent             | "mm"                  |
   +--------------------------+-----------------------------------+-----------------------+
   | snow_depth               | snow depth                        | "m"                   |
   +--------------------------+-----------------------------------+-----------------------+
   | temperature_radiative    | surface radiative temperature     | "K"                   |
   +--------------------------+-----------------------------------+-----------------------+
   | soil_moisture_vol        | volumetric moisture content in    | "m3/m3"               |
   |                          | soil level                        |                       |
   +--------------------------+-----------------------------------+-----------------------+
   | temperature_soil         | temperature in soil               | "K"                   |
   |                          | level                             |                       |
   +--------------------------+-----------------------------------+-----------------------+
   | soil_liquid_vol          | volumetric liquid                 | "m3/m3"               |
   |                          | content in soil level             |                       |
   +--------------------------+-----------------------------------+-----------------------+
   | canopy_water             | canopy moisture                   | "m"                   |
   |                          | content                           |                       |
   +--------------------------+-----------------------------------+-----------------------+
   | transpiration_heat       | plant transpiration               |"W/m2"                 |
   +--------------------------+-----------------------------------+-----------------------+
   | friction_velocity        | friction velocity                 | "m/s"                 |
   +--------------------------+-----------------------------------+-----------------------+
   | z0_total                 | surface roughness                 | "m"                   |
   +--------------------------+-----------------------------------+-----------------------+
   | snow_cover_fraction      | snow cover fraction               | "fraction"            |
   +--------------------------+-----------------------------------+-----------------------+
   | spec_humidity_surface    | diagnostic specific humidity at   | "kg/kg"               |
   |                          | surface                           |                       |
   +--------------------------+-----------------------------------+-----------------------+
   | ground_heat_total        | soil heat flux                    | "W/m2"                |
   +--------------------------+-----------------------------------+-----------------------+
   | runoff_baseflow          | drainage runoff                   | "mm/s"                |
   +--------------------------+-----------------------------------+-----------------------+
   | latent_heat_total        | latent heat flux                  | "W/m2"                |
   +--------------------------+-----------------------------------+-----------------------+
   | sensible_heat_flux       | sensible heat flux                | "W/m2"                |
   +--------------------------+-----------------------------------+-----------------------+
   | evaporation_potential    | potential evaporation             | "mm/s"                |
   +--------------------------+-----------------------------------+-----------------------+
   | runoff_surface           | surface runoff                    | "mm/s"                |
   +--------------------------+-----------------------------------+-----------------------+
   | latent_heat_ground       | direct soil latent heat flux      | "W/m2"                |
   +--------------------------+-----------------------------------+-----------------------+
   | latent_heat_canopy       | canopy water latent heat flux     | "W/m2"                |
   +--------------------------+-----------------------------------+-----------------------+
   | snow_sublimation         | sublimation/deposit from snowpack | "mm/s"                |
   +--------------------------+-----------------------------------+-----------------------+
   | soil_moisture_total      | total soil column moisture        | "mm"                  |
   |                          | content                           |                       |
   +--------------------------+-----------------------------------+-----------------------+
   | precip_adv_heat_total    | precipitation advected heat -     | "W/m2"                |
   |                          | total                             |                       |
   +--------------------------+-----------------------------------+-----------------------+
   | cosine_zenith            | cosine of zenith angle            | "-"                   |
   +--------------------------+-----------------------------------+-----------------------+
   | snow_levels              | active snow levels                | "-"                   |
   +--------------------------+-----------------------------------+-----------------------+
   | temperature_leaf         | leaf temperature                  | "K"                   |
   +--------------------------+-----------------------------------+-----------------------+
   | temperature_ground       | ground temperature                | "K"                   |
   +--------------------------+-----------------------------------+-----------------------+
   | canopy_ice               | canopy ice                        | "mm"                  |
   +--------------------------+-----------------------------------+-----------------------+
   | canopy_liquid            | canopy liquid                     | "mm"                  |
   +--------------------------+-----------------------------------+-----------------------+
   | vapor_pres_canopy_air    |                                   |                       |
   +--------------------------+-----------------------------------+-----------------------+
   | temperature_canopy_air   |                                   |                       |
   +--------------------------+-----------------------------------+-----------------------+
   | canopy_wet_fraction      | fraction of canopy covered by     | "-"                   |
   |                          | water                             |                       |
   +--------------------------+-----------------------------------+-----------------------+
   | snow_water_equiv_old     | snow water equivalent - before    | "mm"                  |
   |                          | integration                       |                       |
   +--------------------------+-----------------------------------+-----------------------+
   | snow_albedo_old          | snow albedo - before integration  | "-"                   |
   +--------------------------+-----------------------------------+-----------------------+
   | snowfall                 | snowfall                          | "mm/s"                |
   +--------------------------+-----------------------------------+-----------------------+
   | lake_water               |                                   |                       |
   +--------------------------+-----------------------------------+-----------------------+
   | depth_water_table        | depth to water table              | "m"                   |
   +--------------------------+-----------------------------------+-----------------------+
   | aquifer_water            | aquifer water content             | "mm"                  |
   +--------------------------+-----------------------------------+-----------------------+
   | saturated_water          | aquifer + saturated soil water    | "mm"                  |
   |                          | content                           |                       |
   +--------------------------+-----------------------------------+-----------------------+
   | leaf_carbon              | carbon in leaves                  | "g/m2"                |
   +--------------------------+-----------------------------------+-----------------------+
   | root_carbon              | carbon in roots                   | "g/m2"                |
   +--------------------------+-----------------------------------+-----------------------+
   | stem_carbon              | carbon in stems                   | "g/m2"                |
   +--------------------------+-----------------------------------+-----------------------+
   | wood_carbon              | carbon in wood                    | "g/m2"                |
   +--------------------------+-----------------------------------+-----------------------+
   | soil_carbon_stable       | stable carbon in soil             | "g/m2"                |
   +--------------------------+-----------------------------------+-----------------------+
   | soil_carbon_fast         | fast carbon in soil               | "g/m2"                |
   +--------------------------+-----------------------------------+-----------------------+
   | leaf_area_index          | leaf area index                   | "m2/m2"               |
   +--------------------------+-----------------------------------+-----------------------+
   | stem_area_index          | stem area index                   | "m2/m2"               |
   +--------------------------+-----------------------------------+-----------------------+
   | snow_age                 | BATS non-dimensional snow age     | "-"                   |
   +--------------------------+-----------------------------------+-----------------------+
   | soil_moisture_wtd        | soil water content between bottom | "m3/m3"               |
   |                          | of the soil and water table       |                       |
   +--------------------------+-----------------------------------+-----------------------+
   | deep_recharge            | deep recharge for runoff_option 5 | "m"                   |
   +--------------------------+-----------------------------------+-----------------------+
   | recharge                 | recharge for runoff_option 5      | "m"                   |
   +--------------------------+-----------------------------------+-----------------------+
   | temperature_2m           | grid diagnostic temperature at 2  | "K"                   |
   |                          | meters                            |                       |
   +--------------------------+-----------------------------------+-----------------------+
   | spec_humidity_2m         | grid diagnostic specific humidity | "kg/kg"               |
   |                          | at 2 meters                       |                       |
   +--------------------------+-----------------------------------+-----------------------+
   | eq_soil_water_vol        | equilibrium soil water content    | "m3/m3"               |
   +--------------------------+-----------------------------------+-----------------------+
   | temperature_snow         | snow level temperature            | "K"                   |
   +--------------------------+-----------------------------------+-----------------------+
   | interface_depth          | layer-bottom depth from snow      | "m"                   |
   |                          | surface                           |                       |
   +--------------------------+-----------------------------------+-----------------------+
   | snow_level_ice           | ice content of snow levels        | "mm"                  |
   +--------------------------+-----------------------------------+-----------------------+
   | snow_level_liquid        | liquid content of snow levels     | "mm"                  |
   +--------------------------+-----------------------------------+-----------------------+

The restart files also include one text file, ``${FILEDATE}.coupler.res``, which contains metadata for the restart.

Example of ``${FILEDATE}.coupler.res``:

.. code-block:: console

   2        (Calendar: no_calendar=0, thirty_day_months=1, julian=2, gregorian=3, noleap=4)
   2016     1     2    18     0     0    Model start time:   year, month, day, hour, minute, second
   2016     1     2    18     0     0    Current model time: year, month, day, hour, minute, second

DA Workflow 
==============
 
The cycling Noah-MP offline DA run is initiated using two shell scripts: ``do_submit_cycle.sh`` and ``submit_cycle.sh``. ``submit_cycle.sh`` calls a third script (``do_landDA.sh``) if DA has been activated in the experiment. 

.. note::
   
   The offline Noah-MP model runs in vector space, whereas a cycling Noah-MP offline DA job uses JEDI's tiled cubed-sphere (:term:`FV3`) format. :numref:`Section %s <VectorTileConverter>` describes the Vector-to-Tile Converter that maps between these two formats. 

``do_submit_cycle.sh``
------------------------

The ``do_submit_cycle.sh`` script sets up the cycling job based on the user's input settings. :numref:`Figure %s <DoSubmitCyclePng>` illustrates the steps in this process. 

.. _DoSubmitCyclePng:

.. figure:: https://github.com/NOAA-EPIC/land-offline_workflow/wiki/do_submit_cycle.png
   :alt: 

   *Flowchart of 'do_submit_cycle.sh'*

.. COMMENT: ADD alt tags!!!

First, ``do_submit_cycle.sh`` reads in a configuration file for the cycle settings. This file contains the information required to run the cycle: the experiment name, start date, end date, the paths of the working directory and output directories, the length of each forecast, atmospheric forcing data, the Finite-Volume Cubed-Sphere Dynamical Core (:term:`FV3`) resolution and its paths, the number of cycles per job, the directory with initial conditions, a namelist file for running Land DA, and different DA options. Then, the required modules are loaded, and some executables are set for running the cycle. The restart frequency and running day/hours are computed from the inputs, and directories are created for running DA and saving the DA outputs. If restart files are not in the experiment output directory, the script will try to copy the restart files from the ``ICSDIR`` directory, which should contain initial conditions files if restart files are not available. Finally, the script creates the dates file (``analdates.sh``) and submits the ``submit_cycle.sh`` script, which is described in detail in the next section.


``submit_cycle.sh``
----------------------

The ``submit_cycle.sh`` script first exports the required paths and loads the required modules. Then, it reads the dates file and runs through all the steps for submitting a cycle if the count of dates is less than the number of cycles per job (see :numref:`Figure %s <SubmitCyclePng>`). 

.. _SubmitCyclePng:

.. figure:: https://github.com/NOAA-EPIC/land-offline_workflow/wiki/submit_cycle.png
   :alt: 

   *Flowchart of 'submit_cycle.sh'*

As the script loops through the steps in the process for each cycle, it reads in the DA settings and selects a run type --- either DA or ``openloop`` (which skips DA). Required DA settings include: DA algorithm choice, directory paths for JEDI, Land_DA (where the ``do_landDA.sh`` script is located), JEDI's input observation options, DA window length, options for constructing ``yaml`` files, etc. 

Next, the system designates work and output directories and copies restart files into the working directory. If the DA option is selected, the script calls the ``vector2tile`` function and tries to convert the format of the Noah-MP model in vector space to the JEDI tile format used in :term:`FV3` cubed-sphere space. After the ``vector2tile`` is done, the script calls the data assimilation job script (``do_landDA.sh``) and runs this script. Then, the ``tile2vector`` function is called and converts the JEDI output tiles back to vector format. The converted vector outputs are saved, and the forecast model is run. Then, the script checks the existing model outputs. Finally, if the current date is less than the end date, this same procedure will be processed for the next cycle.

.. note:: 

   The v1.0.0 release of Land DA does not support ensemble runs. Thus, the first ensemble member is the only ensemble member. 

Here is an example of configuration settings file, ``settings_cycle``, for the ``submit_cycle`` script:

.. code-block:: console
   
   export exp_name=DA_IMS_test
   STARTDATE=2016010118
   ENDDATE=2016010318

   export WORKDIR=/*/*/
   export OUTDIR=/*/*/

   ############################

   # for LETKF, 
   export ensemble_size=1

   export FCSTHR=24

   export atmos_forc=gdas

   #FV3 resolution
   export RES=96
   export TPATH="/*/*/"
   export TSTUB="oro_C96.mx100" 

   # number of cycles 
   export cycles_per_job=1

   # directory with initial conditions
   export ICSDIR=/*/*/

   # namelist for do_landDA.sh
   export DA_config="settings_DA_test"

   # if want different DA at different times, list here. 
   export DA_config00=${DA_config}
   export DA_config06=${DA_config}
   export DA_config12=${DA_config}
   export DA_config18=${DA_config}

Parameters for ``submit_cycle.sh``
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

``exp_name``
   Specifies the name of experiment.

``STARTDATE``
   Specifies the experiment start date. The form is YYYYMMDDHH, where YYYY is a 4-digit year, MM is a valid 2-digit month, DD is a valid 2-digit day, and HH is a valid 2-digit hour. 

``ENDDATE``
   Specifies the experiment end date. The form is YYYYMMDDHH, where YYYY is a 4-digit year, MM is a valid 2-digit month, DD is a valid 2-digit day, and HH is a valid 2-digit hour. 

``WORKDIR``
   Specifies the path to a temporary directory from which the experiment is run.

``OUTDIR``
   Specifies the path to a directory where experiment output is saved.

``ensemble_size``
   Specifies the size of the ensemble (i.e., number of ensemble members). Use ``1`` for non-ensemble runs.

``FCSTHR``
   Specifies the length of each forecast in hours.

``atmos_forc``
   Specifies the name of the atmospheric forcing data. Valid values include: ``GDAS`` | ``ERA5``

``RES``
   Specifies the resolution of FV3. Valid values: ``C96``

   .. note:: 

      Other resolutions are possible but not supported for this release. 

``TPATH``
   Specifies the path to the directory containing the orography files.

``TSTUB``
   Specifies the file stub/name for orography files in ``TPATH``. This file stub is named ``oro_C${RES}`` for atmosphere-only orography files and ``oro_C{RES}.mx100`` for atmosphere and ocean orography files.

``cycles_per_job``
   Specifies the number of cycles to submit in a single job.

``ICSDIR``
   Specifies the path to a directory containing initial conditions data.

``DA_config``
   Specifies the configuration setting file for ``do_landDA.sh``. Set ``DA_config`` to ``openloop`` to skip data assimilation (and prevent a call ``do_landDA.sh``).

``DA_configXX``
   Specifies the configuration setting file for ``do_landDA.sh`` at ``XX`` hr. Set to ``openloop`` to skip data assimilation (and prevent a call ``do_landDA.sh``).


``do_landDA.sh``   
------------------

The ``do_landDA.sh`` runs the data assimilation job inside the ``sumbit_cycle.sh`` script. Currently, the only DA option is the snow Local Ensemble Transform Kalman Filter-Optimal Interpolation (LETKF-OI, :cite:t:`FrolovEtAl2022`). :numref:`Figure %s <DoLandDAPng>` describes the workflow of this script. 

.. _DoLandDAPng:

.. figure:: https://github.com/NOAA-EPIC/land-offline_workflow/wiki/do_landDA.png
   :alt:

   *Flowchart of 'do_landDA.sh'*

.. COMMENT: ADD alt tags!

First, to run the DA job, ``do_landDA.sh`` reads in the configuration file and sets up the directories. The date strings are formatted for the current date and previous date. For each tile, restarts are staged to apply the JEDI update. In this stage, all files will get directly updated. Then, the observation files are read and prepared for this job. 

.. COMMENT: Why is this no longer in the Google doc? 
   For pre-processing, fIMS is called to calculate fractional snow cover on the model grid from the IMS snow cover observations. Then, SWE is calculated from fractional snow cover, assuming the snow depletion curve used by the Noah model. Once this pre-processing job is complete, the script calls the JEDI Interface for Observation Data Access (IODA) converter to provide the interfaces that bridge the differences between the external observation data and the components within JEDI that utilize those data. 

.. COMMENT: Connect the paragraphs above and below...

Once the JEDI type is determined, ``yaml`` files are constructed. Note that if the user specifies a ``yaml`` file, the script uses that one. Otherwise, the script builds the ``yaml`` files.  For LETKF-OI, a pseudo-ensemble is created by running the python script (``letkf_create_ens.py``). Once the ensemble is created, the script runs JEDI and applies increment to UFS restarts.

.. COMMENT: What is SWE?
   How does the script build the YAML itself?
   What is a pseudo-ensemble?

Below, users can find an example of a configuration settings file, ``settings_DA``, for the ``do_landDA.sh`` script:

.. code-block:: console

   LANDDADIR=${CYCLEDIR}/DA_update/ 

   ############################
   # DA options

   OBS_TYPES=("GHCN")   
   JEDI_TYPES=("DA")   

   WINLEN=24

   # YAMLS
   YAML_DA=construct

   # JEDI DIRECTORIES
   JEDI_EXECDIR=   
   fv3bundle_vn=20230106_public 

``LANDDADIR``
   Specifies the path to the ``do_landDA.sh`` script.

``OBS_TYPES``
   Specifies the observation type. Format is "Obs1" "Obs2". Currently, only GHCN observation data is available. 

``JEDI_TYPES``
   Specifies the JEDI call type for each observation type above. Format is "type1" "type2". Valid values: ``DA`` | ``HOFX``

   +--------+--------------------------------------------------------+
   | Value  | Description                                            |
   +========+========================================================+
   | DA     | Data assimilation                                      |
   +--------+--------------------------------------------------------+
   | HOFX   | A generic application for running the model forecast   |
   |        | (or reading forecasts from file) and computing H(x)    |
   +--------+--------------------------------------------------------+

``WINLEN``
   Specifies the DA window length. It is generally the same as the ``FCSTLEN``.

``YAML_DA``
   Specifies whether to construct the ``yaml`` name based on requested observation types and their availabilities. Valid values: ``construct`` | *desired YAML name*

   +--------------------+--------------------------------------------------------+
   | Value              | Description                                            |
   +====================+========================================================+
   | construct          | Enable constructing the YAML                           |
   +--------------------+--------------------------------------------------------+
   | desired YAML name  | Will not test for availability of observations         |
   +--------------------+--------------------------------------------------------+

``JEDI_EXECDIR``
   Specifies the JEDI FV3 build directory. If using different JEDI version, users will need to edit the ``yaml`` files.

   .. COMMENT: The path to this directory or just the name of the directory?

``fv3bundle_vn``
   Specifies the date for ``jedi-fv3`` bundle checkout (used to select correct yaml).

   .. COMMENT: Clarify definition

.. _ConfigureExpt:

Configure the Experiment
===========================

Coming soon!

.. COMMENT: Is this still required?
   #. Create a ``user_build_config`` file:

      .. code-block:: console

         ./configure

   #. Edit the ``user_build_config`` file to setup compiler and library
      paths to be consistent with your environment if not done by default:

      .. code-block:: console

         COMPILERF90 = /opt/local/bin/gfortran-mp-10
         FREESOURCE = #-ffree-form -ffree-line-length-none
         F90FLAGS = -fdefault-real-8 -fdefault-double-8
         NETCDFMOD = -I/opt/local/include
         NETCDFLIB = -L/opt/local/lib -lnetcdf -lnetcdff
         PHYSDIR = ../ccpp-physics/physics

   If users prefer to use a different ``ccpp-physics`` directory from the one
   automatically downloaded with the clone, they can set the ``PHYSDIR`` in
   ``user_build_config`` to point to the top of the ``ccpp-physics``
   directory (path relative to the ``mod`` directory) of their choice.

   All the modules from ``ccpp-physics`` should be compiled in the ``mod``
   directory, all the drivers in the ``driver`` directory, and executables
   are in the ``run`` directory.

.. _SubmitExpt:

Submit the Experiment
========================

Navigate back to the ``land-offline_workflow`` directory and submit the experiment using the ``sbatch`` command. It will run through two cycles (two days).

.. code-block:: console

   cd ..
   sbatch submit_cycle.sh

.. COMMENT: Add info about changing account name and qos (windfall)?

The system will output a message such as ``Submitted batch job ########``, indicating that the job was successfully submitted. If all goes well, a full cycle will run with data assimilation (DA) and a forecast. 

To check on the job status, run: 

.. code-block:: console

   squeue -u $USER

To view progress, users can open the ``log`` and ``err`` files:

.. code-block:: console

   tail -f log* err*

Users will need to hit ``Ctrl+C`` to exit the file. 

.. attention::

   If the log file contains a NetCDF error (e.g., ``ModuleNotFoundError: No module named 'netCDF4'``), run:
   
   .. code-block:: console
      
      python -m pip install netCDF4
   
   Then, resubmit the job (``sbatch submit_cycle.sh``).

Next, check for the background and analysis files in the ``cycle_land`` directory.

.. code-block:: console

   ls -l ../cycle_land/DA_GHCN_test/mem000/restarts/vector/

